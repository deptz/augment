# JIRA Configuration (Required)
JIRA_SERVER_URL=https://your-company.atlassian.net
JIRA_USERNAME=your-email@company.com
JIRA_API_TOKEN=your-jira-api-token
JIRA_PRD_CUSTOM_FIELD=customfield_10001
JIRA_RFC_CUSTOM_FIELD=
JIRA_TEST_CASE_CUSTOM_FIELD=
JIRA_MANDAYS_CUSTOM_FIELD=

# Bitbucket Configuration (Optional)
# Used for fetching pull requests and commit information
# For multiple workspaces, use comma-separated list:
BITBUCKET_WORKSPACES=workspace1,workspace2
# OR for single workspace (backward compatible):
# BITBUCKET_WORKSPACE=your-workspace
BITBUCKET_EMAIL=your-email@company.com
BITBUCKET_API_TOKEN=your-atlassian-api-token

# Confluence Configuration (Optional)
# Used for fetching PRD/RFC content from Confluence pages
CONFLUENCE_SERVER_URL=https://your-company.atlassian.net/wiki
CONFLUENCE_USERNAME=your-email@company.com
CONFLUENCE_API_TOKEN=your-confluence-api-token

# LLM Configuration (Required)
# Choose one provider: openai, claude, gemini, or kimi
LLM_PROVIDER=openai

# OpenAI Configuration
OPENAI_API_KEY=your-openai-api-key
OPENAI_MODEL=gpt-5-mini

# Anthropic (Claude) Configuration
ANTHROPIC_API_KEY=your-anthropic-api-key
ANTHROPIC_MODEL=claude-sonnet-4-5

# Google (Gemini) Configuration
GOOGLE_API_KEY=your-google-api-key
GOOGLE_MODEL=gemini-2.0-flash-exp

# Moonshot AI (KIMI) Configuration
MOONSHOT_API_KEY=your-moonshot-api-key
MOONSHOT_MODEL=moonshot-v1-8k

# LLM Advanced Configuration (Optional)
LLM_SYSTEM_PROMPT=You are a technical documentation assistant specializing in creating structured Jira ticket descriptions from historical development artifacts.
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=

# Processing Configuration (Optional)
MAX_CONCURRENT_REQUESTS=5
REQUEST_TIMEOUT=30
BATCH_SIZE=10
INCLUDE_CODE_ANALYSIS=true
STORY_DESCRIPTION_MAX_LENGTH=800
STORY_DESCRIPTION_SUMMARY_THRESHOLD=1200
MAX_TASKS_PER_STORY=10

# Authentication Configuration (Optional)
# Enable HTTP Basic Authentication for API endpoints
AUTH_ENABLED=false
AUTH_USERNAME=admin
AUTH_PASSWORD_HASH=

# Redis Configuration (Required for background jobs)
# Used for ARQ background job queue
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_DB=0

# Worker Configuration (Optional)
# ARQ worker process settings
WORKER_MAX_JOBS=10
WORKER_JOB_TIMEOUT=3600
WORKER_KEEP_RESULT=3600

# Sprint Planning Configuration (Optional)
SPRINT_DURATION_DAYS=14
TEAM_CAPACITY_DAYS=10.0
AUTO_CREATE_SPRINTS=false

# Environment Settings (Optional)
ENVIRONMENT=development

# Team Member Database (Optional)
# Custom database path (absolute or relative to project root)
# Default: data/team_members.db
TEAM_MEMBER_DB_PATH=

#CORS Allowed Origin setting
# Comma-separated list of allowed origins for Cross-Origin Resource Sharing
# Example: http://localhost:5173,http://localhost:3000,https://example.com
# If not set, defaults to common localhost ports for development
CORS_ALLOWED_ORIGINS=http://localhost:5173,http://localhost:3000
# OpenCode Integration (Optional)
# Enable code-aware LLM generation using OpenCode Docker containers

# OpenCode Integration (Optional)
# Enable code-aware LLM generation using OpenCode Docker containers
OPENCODE_ENABLED=false
OPENCODE_DOCKER_IMAGE=ghcr.io/anomalyco/opencode
OPENCODE_MAX_CONCURRENT=2
OPENCODE_MAX_REPOS=5
OPENCODE_TIMEOUT=20
OPENCODE_CLONE_TIMEOUT=300
OPENCODE_SHALLOW_CLONE=true
OPENCODE_MAX_RESULT_SIZE=10
OPENCODE_DEBUG_LOGGING=false  # Enable conversation logging for debugging (saves to logs/opencode/)
OPENCODE_LOG_DIR=logs/opencode  # Directory for conversation log files

# OpenCode-Specific LLM Configuration (REQUIRED - separate from main LLM config)
OPENCODE_LLM_PROVIDER=claude  # REQUIRED: Options: openai, claude, gemini, kimi
OPENCODE_ANTHROPIC_API_KEY=sk-ant-api03-...  # REQUIRED if provider=claude
OPENCODE_ANTHROPIC_MODEL=claude-haiku-4-5  # REQUIRED if provider=claude
# OR for other providers:
# OPENCODE_OPENAI_API_KEY=sk-...  # REQUIRED if provider=openai
# OPENCODE_OPENAI_MODEL=gpt-5-mini  # REQUIRED if provider=openai
# OPENCODE_GOOGLE_API_KEY=...  # REQUIRED if provider=gemini
# OPENCODE_GOOGLE_MODEL=gemini-2.5-flash  # REQUIRED if provider=gemini
# OPENCODE_MOONSHOT_API_KEY=...  # REQUIRED if provider=kimi
# OPENCODE_MOONSHOT_MODEL=moonshot-v1-8k  # REQUIRED if provider=kimi

OPENCODE_LLM_TEMPERATURE=0.7  # Optional: defaults to 0.7
OPENCODE_LLM_MAX_TOKENS=  # Optional: uses provider defaults if not set

# Git Credentials for OpenCode (Required for private repositories)
# These credentials are used when cloning repositories via HTTPS
# Works with any Git provider: Bitbucket, GitHub, GitLab, etc.
#
# For Bitbucket:
#   GIT_USERNAME = Your Bitbucket username or email
#   GIT_PASSWORD = Bitbucket App Password (create at: https://bitbucket.org/account/settings/app-passwords/)
#
# For GitHub:
#   GIT_USERNAME = Your GitHub username
#   GIT_PASSWORD = Personal Access Token (create at: https://github.com/settings/tokens)
#
# For GitLab:
#   GIT_USERNAME = Your GitLab username
#   GIT_PASSWORD = Personal Access Token (create at: https://gitlab.com/-/profile/personal_access_tokens)
#
GIT_USERNAME=
GIT_PASSWORD=

MCP_NETWORK_NAME=augment-mcp-network

# MCP Server Configuration
MCP_BITBUCKET_ENABLED=true
MCP_BITBUCKET_URL=http://bitbucket-mcp:7001/mcp
MCP_BITBUCKET_HOSTNAME=bitbucket-mcp
MCP_BITBUCKET_PORT=7001
MCP_BITBUCKET_IMAGE=node:20-alpine  # Optional: defaults to node:20-alpine

MCP_ATLASSIAN_ENABLED=true
MCP_ATLASSIAN_URL=http://atlassian-mcp:7002/mcp
MCP_ATLASSIAN_HOSTNAME=atlassian-mcp
MCP_ATLASSIAN_PORT=7002
MCP_ATLASSIAN_IMAGE=ghcr.io/sooperset/mcp-atlassian:latest  # Optional: defaults to ghcr.io/sooperset/mcp-atlassian:latest

MCP_MAX_CALLS=50



# ============================================================================
# MCP Server Read-Only Credentials (REQUIRED for MCP servers)
# ============================================================================
# IMPORTANT: MCP servers require SEPARATE read-only credentials with MCP_ prefix.
# These credentials MUST have READ-ONLY permissions/scopes to enforce read-only access.
# The main application uses separate credentials (above) that may have write permissions.
#
# URLs (JIRA_SERVER_URL, CONFLUENCE_SERVER_URL, BITBUCKET_URL) are shared from main app
# configuration above and do NOT need to be duplicated here.

# JIRA Read-Only Credentials (REQUIRED)
MCP_JIRA_USERNAME=your.readonly.email@company.com
MCP_JIRA_API_TOKEN=your_readonly_jira_api_token

# Confluence Read-Only Credentials (Optional - defaults to JIRA credentials if not set)
# MCP_CONFLUENCE_USERNAME=your.readonly.email@company.com
# MCP_CONFLUENCE_API_TOKEN=your_readonly_confluence_api_token

# Bitbucket Read-Only Credentials (REQUIRED)
MCP_BITBUCKET_EMAIL=your.readonly.email@company.com
MCP_BITBUCKET_API_TOKEN=your_readonly_bitbucket_app_password

# ============================================================================
# Required API Token Scopes for Read-Only Access
# ============================================================================
# When creating MCP credentials, ensure they have READ-ONLY permissions:
#
# JIRA:
#   - Read-only access to issues, projects, boards
#   - NO write, delete, or admin permissions
#
# Confluence:
#   - Read-only access to pages, spaces
#   - NO write, delete, or admin permissions
#
# Bitbucket:
#   - Repositories: Read (only)
#   - Pull requests: Read (only)
#   - Commits: Read (only)
#   - NO write, delete, or admin permissions

# Multi-Workspace Support:
# If BITBUCKET_WORKSPACES contains multiple workspaces (comma-separated),
# the system will automatically create one Bitbucket MCP instance per workspace.
# Each instance gets a unique port (7001, 7002, 7003...) and hostname (bitbucket-mcp-{workspace}).
# Example: BITBUCKET_WORKSPACES=workspace1,workspace2,workspace3
#   Creates: bitbucket-mcp-workspace1 (port 7001), bitbucket-mcp-workspace2 (port 7002), etc.
